{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:36:17.092657: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import tqdm\n",
    "\n",
    "import ase\n",
    "from ase import io\n",
    "from ase import data\n",
    "from ase import db\n",
    "from ase.visualize.plot import plot_atoms\n",
    "\n",
    "from skimage import feature\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ml_collections\n",
    "from clu import checkpoint\n",
    "\n",
    "\n",
    "from molnet import utils, train_state, train\n",
    "from molnet.data import input_pipeline_online\n",
    "from molnet.models import create_model\n",
    "from configs import root_dirs\n",
    "from analyses import make_predictions\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "INDEX_TO_SYMBOL = {\n",
    "    0: 'H',\n",
    "    1: 'C',\n",
    "    2: 'N',\n",
    "    3: 'O',\n",
    "    4: 'F'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = \"/u/79/kurkil1/unix/work/molnet/runs/bf16-augs-rebias-adam-3e-4-z10-reverse-z/\"\n",
    "#workdir = \"/u/79/kurkil1/unix/work/molnet/runs/bf16-augs-rebias-adam-3e-4-z20-interp/\"\n",
    "#workdir = \"/Users/kurkil1/work/molnet/runs/attention-adam-3e-4/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_workdir(\n",
    "    workdir: str,\n",
    "    return_attention: bool\n",
    "):\n",
    "    # Load the model config\n",
    "    with open(os.path.join(workdir, \"config.yaml\"), \"rt\") as f:\n",
    "        config = yaml.unsafe_load(f)\n",
    "    config = ml_collections.ConfigDict(config)\n",
    "    config.root_dir = root_dirs.get_root_dir(\"afms_rebias\")\n",
    "    config.model.return_attention_maps = return_attention\n",
    "\n",
    "    print(config)\n",
    "\n",
    "    # Create the model\n",
    "    model = create_model(config.model)\n",
    "\n",
    "    checkpoint_dir = os.path.join(workdir, \"checkpoints\")\n",
    "    ckpt = checkpoint.Checkpoint(checkpoint_dir)\n",
    "\n",
    "    apply_fn = model.apply\n",
    "    tx = utils.create_optimizer(config)\n",
    "    restored_state = ckpt.restore(state=None)['state']\n",
    "\n",
    "    # Load the model state\n",
    "    state = train_state.EvaluationState.create(\n",
    "        apply_fn=apply_fn,\n",
    "        params=restored_state['params'],\n",
    "        batch_stats=restored_state['batch_stats'],\n",
    "        tx=tx,\n",
    "    )\n",
    "    state = jax.tree_util.tree_map(jnp.asarray, state)\n",
    "\n",
    "    return state, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 12\n",
      "cutout_probs:\n",
      "- 0.5\n",
      "- 0.3\n",
      "- 0.1\n",
      "- 0.05\n",
      "- 0.05\n",
      "dataset: afms_rebias\n",
      "debug: false\n",
      "eval_every_steps: 2000\n",
      "gaussian_factor: 5.0\n",
      "interpolate_input_z: null\n",
      "learning_rate: 0.0003\n",
      "learning_rate_schedule: constant\n",
      "learning_rate_schedule_kwargs:\n",
      "  decay_steps: 50000\n",
      "  init_value: 0.0003\n",
      "  peak_value: 0.0006\n",
      "  warmup_steps: 2000\n",
      "log_every_steps: 100\n",
      "loss_fn: mse\n",
      "max_atoms: 54\n",
      "max_shift_per_slice: 0.02\n",
      "model:\n",
      "  attention_activation: sigmoid\n",
      "  attention_channels:\n",
      "  - 32\n",
      "  - 32\n",
      "  - 32\n",
      "  - 32\n",
      "  - 32\n",
      "  conv_activation: relu\n",
      "  decoder_channels:\n",
      "  - 256\n",
      "  - 128\n",
      "  - 64\n",
      "  - 32\n",
      "  - 16\n",
      "  decoder_kernel_size:\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  dtype: bfloat16\n",
      "  encoder_channels:\n",
      "  - 16\n",
      "  - 32\n",
      "  - 64\n",
      "  - 128\n",
      "  - 256\n",
      "  encoder_kernel_size:\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  model_name: Attention-UNet\n",
      "  output_activation: null\n",
      "  output_channels: 5\n",
      "  return_attention_maps: false\n",
      "momentum: null\n",
      "noise_std: 0.1\n",
      "num_eval_steps: 100\n",
      "num_train_steps: 1000000\n",
      "optimizer: adam\n",
      "peak_threshold: 0.5\n",
      "predict_every_steps: 10000\n",
      "predict_num_batches: 2\n",
      "predict_num_batches_at_end_of_training: 10\n",
      "rng_seed: 0\n",
      "root_dir: /l/data/molnet/afms_rebias/\n",
      "shuffle_datasets: true\n",
      "sigma: 0.2\n",
      "train_molecules: !!python/tuple\n",
      "- 0\n",
      "- 80000\n",
      "val_molecules: !!python/tuple\n",
      "- 80000\n",
      "- 100000\n",
      "z_cutoff: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:36:43.294256: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "state, config = load_from_workdir(\n",
    "    workdir=workdir,\n",
    "    return_attention=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 18085879115725111131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images (12, 128, 128, 10, 1)\n",
      "xyz (12, 54, 5)\n",
      "sw (12, 2, 3)\n",
      "atom_map (12, 128, 128, 10, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 17927960504738319970\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 7709568092925371842\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 1400486575639093112\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 3109770934328084305\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 18281604661472889738\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12804067205872363779\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 1861181575705745322\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 562762232596408869\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 4907955943831455628\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 14462771483250533871\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 14015997285969731913\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 1363218185392474230\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 15342347715217193868\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 10083096188548548466\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9758011030649576394\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 4780390786448074850\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 1219268742183260596\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 6355647068608642872\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "datarng, rng = jax.random.split(rng)\n",
    "with config.unlocked():\n",
    "    #config.z_cutoff = 1.0\n",
    "    #config.interpolate_z = None\n",
    "    config.target_z_cutoff = 1.0\n",
    "    #config.train_molecules = (0, 80000)\n",
    "    #config.val_molecules = (80000, 100000)\n",
    "    #config.max_shift_per_slice = 0.02\n",
    "\n",
    "ds = input_pipeline_online.get_full_molecule_datasets(\n",
    "    config\n",
    ")['val']\n",
    "\n",
    "batch = next(ds)\n",
    "\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_to_mol(\n",
    "    grid: jnp.ndarray,\n",
    "    peak_threshold: float = 0.5,\n",
    "    z_cutoff: float = 1.0,\n",
    ") -> ase.Atoms:\n",
    "    grid = grid[..., ::-1, :]\n",
    "\n",
    "    peaks = feature.peak_local_max(\n",
    "        grid,\n",
    "        min_distance=5,\n",
    "        exclude_border=0,\n",
    "        threshold_rel=peak_threshold\n",
    "    )\n",
    "\n",
    "    xyz_from_peaks = peaks[:, [1, 0, 2]] * (.125, .125, .1)\n",
    "    elem_from_peaks = peaks[:, 3]\n",
    "\n",
    "    mol = ase.Atoms(\n",
    "        positions=xyz_from_peaks,\n",
    "        symbols=[INDEX_TO_SYMBOL[i] for i in elem_from_peaks],\n",
    "        cell=[16, 16, 0],\n",
    "    )\n",
    "    mol.positions[:, 2] -= mol.get_positions()[:, 2].max() - z_cutoff\n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def predict(\n",
    "    state,\n",
    "    batch,\n",
    "):\n",
    "    inputs, targets = batch['images'], batch['atom_map']\n",
    "    preds = state.apply_fn(\n",
    "        {'params': state.params, 'batch_stats': state.batch_stats},\n",
    "        inputs,\n",
    "        training=False,\n",
    "    )\n",
    "    return inputs, targets, preds, batch[\"xyz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:36:48.733069: W external/xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-02-05 14:36:54.652687: W external/xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.66GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-02-05 14:36:54.925324: W external/xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.12GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-02-05 14:36:55.672451: W external/xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.57GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-02-05 14:36:55.672941: W external/xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-02-05 14:36:56.126343: W external/xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    }
   ],
   "source": [
    "inputs, targets, preds, xyz = predict(state, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(inputs.shape[0]):\n",
    "    fig = plt.figure(figsize=(20, 2))\n",
    "    for z in range(preds.shape[-2]):\n",
    "        ax = plt.subplot(2, 10, z+1)\n",
    "        ax.imshow(inputs[i, ..., z, 0], origin='lower')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"H\", \"C\", \"N\", \"O\", \"F\"]\n",
    "for i in range(inputs.shape[0]):\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "\n",
    "    for s in range(preds.shape[-1]):\n",
    "        ax = plt.subplot(2, 5, s + 1)\n",
    "        ax.imshow(preds[i, ..., s].sum(-1), origin='lower', cmap='viridis')\n",
    "\n",
    "        if s == 0:\n",
    "            ax.set_title(\"Predictions, H\")\n",
    "        else:\n",
    "            ax.set_title(f\"{labels[s]}\")\n",
    "\n",
    "        ax = plt.subplot(2, 5, s + 6)\n",
    "        ax.imshow(targets[i, ..., s].sum(-1), origin='lower', cmap='viridis')\n",
    "\n",
    "        if s == 0:\n",
    "            ax.set_title(\"Targets, H\")\n",
    "        else:\n",
    "            ax.set_title(f\"{labels[s]}\")\n",
    "    \n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(inputs.shape[0]):\n",
    "    fig = plt.figure(figsize=(20, 2))\n",
    "    for z in range(preds.shape[-2]):\n",
    "        ax = plt.subplot(2, 10, z+1)\n",
    "        ax.imshow(preds[i, ..., z, :].sum(-1).T, origin='lower', vmin=0, vmax=5)\n",
    "\n",
    "        ax = plt.subplot(2, 10, z+11)\n",
    "        ax.imshow(targets[i, ..., z, :].sum(-1).T, origin='lower', vmin=0, vmax=5)\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-2.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
