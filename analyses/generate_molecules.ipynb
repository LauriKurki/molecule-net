{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 17:48:04.937298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import tqdm\n",
    "\n",
    "import ase\n",
    "from ase import io\n",
    "from ase import data\n",
    "from ase import db\n",
    "from ase.visualize.plot import plot_atoms\n",
    "\n",
    "from skimage import feature\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ml_collections\n",
    "from clu import checkpoint\n",
    "\n",
    "\n",
    "from molnet import utils, train_state, train\n",
    "from molnet.data import input_pipeline_online\n",
    "from molnet.models import create_model\n",
    "from configs import root_dirs\n",
    "from analyses import make_predictions\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "INDEX_TO_SYMBOL = {\n",
    "    0: 'H',\n",
    "    1: 'C',\n",
    "    2: 'N',\n",
    "    3: 'O',\n",
    "    4: 'F'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = \"/u/79/kurkil1/unix/work/molnet/runs/bf16-augs-rebias-adam-3e-4-z10-reverse-z/\"\n",
    "workdir = \"/u/79/kurkil1/unix/work/molnet/runs/bf16-augs-rebias-adam-3e-4-z20-interp/\"\n",
    "#workdir = \"/Users/kurkil1/work/molnet/runs/attention-adam-3e-4/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_workdir(\n",
    "    workdir: str,\n",
    "    return_attention: bool\n",
    "):\n",
    "    # Load the model config\n",
    "    with open(os.path.join(workdir, \"config.yaml\"), \"rt\") as f:\n",
    "        config = yaml.unsafe_load(f)\n",
    "    config = ml_collections.ConfigDict(config)\n",
    "    config.root_dir = root_dirs.get_root_dir(\"afms_rebias\")\n",
    "    config.model.return_attention_maps = return_attention\n",
    "\n",
    "    print(config)\n",
    "\n",
    "    # Create the model\n",
    "    model = create_model(config.model)\n",
    "\n",
    "    checkpoint_dir = os.path.join(workdir, \"checkpoints\")\n",
    "    ckpt = checkpoint.Checkpoint(checkpoint_dir)\n",
    "\n",
    "    apply_fn = model.apply\n",
    "    tx = utils.create_optimizer(config)\n",
    "    restored_state = ckpt.restore(state=None)['state']\n",
    "\n",
    "    # Load the model state\n",
    "    state = train_state.EvaluationState.create(\n",
    "        apply_fn=apply_fn,\n",
    "        params=restored_state['params'],\n",
    "        batch_stats=restored_state['batch_stats'],\n",
    "        tx=tx,\n",
    "    )\n",
    "    state = jax.tree_util.tree_map(jnp.asarray, state)\n",
    "\n",
    "    return state, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 12\n",
      "cutout_probs:\n",
      "- 0.5\n",
      "- 0.3\n",
      "- 0.1\n",
      "- 0.05\n",
      "- 0.05\n",
      "dataset: afms_rebias\n",
      "debug: false\n",
      "eval_every_steps: 2000\n",
      "gaussian_factor: 5.0\n",
      "interpolate_input_z: 20\n",
      "learning_rate: 0.0003\n",
      "learning_rate_schedule: constant\n",
      "learning_rate_schedule_kwargs:\n",
      "  decay_steps: 50000\n",
      "  init_value: 0.0003\n",
      "  peak_value: 0.0006\n",
      "  warmup_steps: 2000\n",
      "log_every_steps: 100\n",
      "loss_fn: mse\n",
      "max_atoms: 54\n",
      "max_shift_per_slice: 0.02\n",
      "model:\n",
      "  attention_activation: sigmoid\n",
      "  attention_channels:\n",
      "  - 32\n",
      "  - 32\n",
      "  - 32\n",
      "  - 32\n",
      "  - 32\n",
      "  conv_activation: relu\n",
      "  decoder_channels:\n",
      "  - 256\n",
      "  - 128\n",
      "  - 64\n",
      "  - 32\n",
      "  - 16\n",
      "  decoder_kernel_size:\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  dtype: bfloat16\n",
      "  encoder_channels:\n",
      "  - 16\n",
      "  - 32\n",
      "  - 64\n",
      "  - 128\n",
      "  - 256\n",
      "  encoder_kernel_size:\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  - - 3\n",
      "    - 3\n",
      "    - 3\n",
      "  model_name: Attention-UNet\n",
      "  output_activation: null\n",
      "  output_channels: 5\n",
      "  return_attention_maps: false\n",
      "momentum: null\n",
      "noise_std: 0.1\n",
      "num_eval_steps: 100\n",
      "num_train_steps: 1000000\n",
      "optimizer: adam\n",
      "peak_threshold: 0.5\n",
      "predict_every_steps: 10000\n",
      "predict_num_batches: 2\n",
      "predict_num_batches_at_end_of_training: 10\n",
      "rng_seed: 0\n",
      "root_dir: /l/data/molnet/afms_rebias/\n",
      "shuffle_datasets: true\n",
      "sigma: 0.2\n",
      "train_molecules: !!python/tuple\n",
      "- 0\n",
      "- 80000\n",
      "val_molecules: !!python/tuple\n",
      "- 80000\n",
      "- 100000\n",
      "z_cutoff: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state, config = load_from_workdir(\n",
    "    workdir=workdir,\n",
    "    return_attention=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 18085879115725111131\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 1400486575639093112\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 17927960504738319970\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 4780390786448074850\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 3109770934328084305\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 15342347715217193868\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 1363218185392474230\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 14462771483250533871\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 14015997285969731913\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 18281604661472889738\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 1219268742183260596\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 6355647068608642872\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 10083096188548548466\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 4907955943831455628\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9758011030649576394\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12804067205872363779\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 562762232596408869\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 1861181575705745322\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 7709568092925371842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images (12, 128, 128, 20, 1)\n",
      "xyz (12, 54, 5)\n",
      "sw (12, 2, 3)\n",
      "atom_map (12, 128, 128, 20, 5)\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "datarng, rng = jax.random.split(rng)\n",
    "with config.unlocked():\n",
    "    #config.z_cutoff = 1.0\n",
    "    #config.interpolate_z = None\n",
    "    config.target_z_cutoff = 2.0\n",
    "    #config.train_molecules = (0, 80000)\n",
    "    #config.val_molecules = (80000, 100000)\n",
    "    #config.max_shift_per_slice = 0.02\n",
    "\n",
    "ds = input_pipeline_online.get_full_molecule_datasets(\n",
    "    config\n",
    ")['val']\n",
    "\n",
    "batch = next(ds)\n",
    "\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_to_mol(\n",
    "    grid: jnp.ndarray,\n",
    "    peak_threshold: float = 0.5,\n",
    "    z_cutoff: float = 1.0,\n",
    ") -> ase.Atoms:\n",
    "    grid = grid[..., ::-1, :]\n",
    "\n",
    "    peaks = feature.peak_local_max(\n",
    "        grid,\n",
    "        min_distance=5,\n",
    "        exclude_border=0,\n",
    "        threshold_rel=peak_threshold\n",
    "    )\n",
    "\n",
    "    xyz_from_peaks = peaks[:, [1, 0, 2]] * (.125, .125, .1)\n",
    "    elem_from_peaks = peaks[:, 3]\n",
    "\n",
    "    mol = ase.Atoms(\n",
    "        positions=xyz_from_peaks,\n",
    "        symbols=[INDEX_TO_SYMBOL[i] for i in elem_from_peaks],\n",
    "        cell=[16, 16, 0],\n",
    "    )\n",
    "    mol.positions[:, 2] -= mol.get_positions()[:, 2].max() - z_cutoff\n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def predict(\n",
    "    state,\n",
    "    batch,\n",
    "):\n",
    "    inputs, targets = batch['images'], batch['atom_map']\n",
    "    preds = state.apply_fn(\n",
    "        {'params': state.params, 'batch_stats': state.batch_stats},\n",
    "        inputs,\n",
    "        training=False,\n",
    "    )\n",
    "    return inputs, targets, preds, batch[\"xyz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 18:01:20.149186: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (bf16[12,128,16,16,20]{4,3,2,1,0}, u8[0]{0}) custom-call(bf16[12,288,16,16,20]{4,3,2,1,0}, bf16[128,288,3,3,3]{4,3,2,1,0}, bf16[128]{0}), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-02-04 18:01:20.646019: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.496926946s\n",
      "Trying algorithm eng0{} for conv (bf16[12,128,16,16,20]{4,3,2,1,0}, u8[0]{0}) custom-call(bf16[12,288,16,16,20]{4,3,2,1,0}, bf16[128,288,3,3,3]{4,3,2,1,0}, bf16[128]{0}), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-02-04 18:01:27.380730: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (bf16[12,32,128,128,20]{4,3,2,1,0}, u8[0]{0}) custom-call(bf16[12,16,128,128,20]{4,3,2,1,0}, bf16[32,16,3,3,3]{4,3,2,1,0}, bf16[32]{0}), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-02-04 18:01:27.858785: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.478113746s\n",
      "Trying algorithm eng0{} for conv (bf16[12,32,128,128,20]{4,3,2,1,0}, u8[0]{0}) custom-call(bf16[12,16,128,128,20]{4,3,2,1,0}, bf16[32,16,3,3,3]{4,3,2,1,0}, bf16[32]{0}), window={size=3x3x3 pad=1_1x1_1x1_1}, dim_labels=bf012_oi012->bf012, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kRelu\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      " 31%|███       | 310/1000 [07:21<16:23,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputdir = os.path.join(workdir, \"ase_0.3\")\n",
    "# Create the output directory\n",
    "os.makedirs(outputdir, exist_ok=True)\n",
    "\n",
    "# Create 3 dbs\n",
    "# 1. Target molecules\n",
    "# 2. Predicted molecules\n",
    "# 3. Molecules from xyz\n",
    "\n",
    "xyz_target = os.path.join(outputdir, \"target.xyz\")\n",
    "xyz_pred = os.path.join(outputdir, \"pred.xyz\")\n",
    "#xyz_full = os.path.join(outputdir, \"full.xyz\")\n",
    "\n",
    "for i in tqdm.tqdm(range(1000)):\n",
    "    try:\n",
    "        batch = next(ds)\n",
    "    except StopIteration:\n",
    "        print(\"End of dataset\")\n",
    "        break\n",
    "    inputs, targets, preds, xyzs = predict(state, batch)\n",
    "    target_mols = [\n",
    "        grid_to_mol(t, z_cutoff=1.0, peak_threshold=0.3) for t in targets\n",
    "    ]\n",
    "    pred_mols = [\n",
    "        grid_to_mol(p, z_cutoff=1.0, peak_threshold=0.3) for p in preds\n",
    "    ]\n",
    "    #full_mols = [\n",
    "    #    ase.Atoms(\n",
    "    #        positions=xyz[xyz[:, -1] > 0, :3],\n",
    "    #        numbers=xyz[xyz[:, -1] > 0, -1],\n",
    "    #    ) for xyz in xyzs\n",
    "    #]\n",
    "\n",
    "    # Write the molecules to the xyz files\n",
    "    io.write(xyz_target, target_mols, format=\"extxyz\", append=True)\n",
    "    io.write(xyz_pred, pred_mols, format=\"extxyz\", append=True)\n",
    "    #io.write(xyz_full, full_mols, format=\"extxyz\", append=True)\n",
    "\n",
    "    #for j in range(inputs.shape[0]):\n",
    "    #    fig = plt.figure(figsize=(10, 5))\n",
    "    #    subfigs = fig.subfigures(1, 2, wspace=0.1, hspace=0.1)\n",
    "    #    ax = subfigs[0].add_subplot(111)\n",
    "    #    ax.imshow(inputs[j, ..., -1, 0], origin='lower', cmap='gray')\n",
    "    #    ax = subfigs[1].add_subplot(231)\n",
    "    #    plot_atoms(target_mols[j], ax=ax, show_unit_cell=2)\n",
    "    #    ax = subfigs[1].add_subplot(234)        \n",
    "    #    plot_atoms(target_mols[j], ax=ax, rotation='-90x', show_unit_cell=2)\n",
    "    #    ax = subfigs[1].add_subplot(232)\n",
    "    #    plot_atoms(pred_mols[j], ax=ax, show_unit_cell=2)\n",
    "    #    \n",
    "    #    ax = subfigs[1].add_subplot(235)\n",
    "    #    plot_atoms(pred_mols[j], ax=ax, rotation='-90x', show_unit_cell=2)\n",
    "    #    ax = subfigs[1].add_subplot(233)\n",
    "    #    plot_atoms(full_mols[j], ax=ax, show_unit_cell=2)\n",
    "    #    ax = subfigs[1].add_subplot(236)\n",
    "    #    plot_atoms(full_mols[j], ax=ax, rotation='-90x', show_unit_cell=2)\n",
    "    #    plt.tight_layout()\n",
    "    #    plt.savefig(f'{outputdir}/mol_{i}_{j}.png')\n",
    "    #    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-2.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
