{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import escnn\n",
    "from escnn import gspaces\n",
    "from escnn import nn as enn\n",
    "from escnn.nn import EquivariantModule, FieldType\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormMaxPool(EquivariantModule):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 in_type: FieldType,\n",
    "                 kernel_size,\n",
    "                 stride=None,\n",
    "                 padding=0,\n",
    "                 dilation = 1,\n",
    "                 ceil_mode = False,\n",
    "                 ):\n",
    "        r\"\"\"\n",
    "        \n",
    "        Max-pooling based on the fields' norms. In a given window of shape :attr:`kernel_size`, for each\n",
    "        group of channels belonging to the same field, the field with the highest norm (as the length of the vector)\n",
    "        is preserved.\n",
    "        \n",
    "        Except :attr:`in_type`, the other parameters correspond to the ones of :class:`torch.nn.MaxPool2d`.\n",
    "        \n",
    "        .. warning ::\n",
    "            Even if the input tensor has a `coords` attribute, the output of this module will not have one.\n",
    "            \n",
    "        Args:\n",
    "            in_type (FieldType): the input field type\n",
    "            kernel_size: the size of the window to take a max over\n",
    "            stride: the stride of the window. Default value is :attr:`kernel_size`\n",
    "            padding: implicit zero padding to be added on both sides\n",
    "            dilation: a parameter that controls the stride of elements in the window\n",
    "            ceil_mode: when ``True``, will use ceil instead of floor to compute the output shape\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        assert isinstance(in_type.gspace, escnn.gspaces.GSpace)\n",
    "        assert in_type.gspace.dimensionality == 2\n",
    "\n",
    "        super(NormMaxPool, self).__init__()\n",
    "\n",
    "        self.space = in_type.gspace\n",
    "        self.in_type = in_type\n",
    "        self.out_type = in_type\n",
    "\n",
    "        if isinstance(kernel_size, int):\n",
    "            self.kernel_size = (kernel_size, kernel_size)\n",
    "        else:\n",
    "            self.kernel_size = kernel_size\n",
    "        \n",
    "        if isinstance(stride, int):\n",
    "            self.stride = (stride, stride)\n",
    "        elif stride is None:\n",
    "            self.stride = self.kernel_size\n",
    "        else:\n",
    "            self.stride = stride\n",
    "        \n",
    "        if isinstance(padding, int):\n",
    "            self.padding = (padding, padding)\n",
    "        else:\n",
    "            self.padding = padding\n",
    "        \n",
    "        if isinstance(dilation, int):\n",
    "            self.dilation = (dilation, dilation)\n",
    "        else:\n",
    "            self.dilation = dilation\n",
    "            \n",
    "        self.ceil_mode = ceil_mode\n",
    "        \n",
    "        self._nfields = None\n",
    "        \n",
    "        # group fields by their size and\n",
    "        #   - check if fields of the same size are contiguous\n",
    "        #   - retrieve the indices of the fields\n",
    "\n",
    "        # number of fields of each size\n",
    "        self._nfields = defaultdict(int)\n",
    "        \n",
    "        # indices of the channales corresponding to fields belonging to each group\n",
    "        _indices = defaultdict(lambda: [])\n",
    "        \n",
    "        # whether each group of fields is contiguous or not\n",
    "        self._contiguous = {}\n",
    "        \n",
    "        position = 0\n",
    "        last_size = None\n",
    "        for i, r in enumerate(self.in_type.representations):\n",
    "            \n",
    "            if r.size != last_size:\n",
    "                if not r.size in self._contiguous:\n",
    "                    self._contiguous[r.size] = True\n",
    "                else:\n",
    "                    self._contiguous[r.size] = False\n",
    "            last_size = r.size\n",
    "            \n",
    "            _indices[r.size] += list(range(position, position + r.size))\n",
    "            self._nfields[r.size] += 1\n",
    "            position += r.size\n",
    "        \n",
    "        for s, contiguous in self._contiguous.items():\n",
    "            if contiguous:\n",
    "                # for contiguous fields, only the first and last indices are kept\n",
    "                _indices[s] = torch.LongTensor([min(_indices[s]), max(_indices[s])+1])\n",
    "            else:\n",
    "                # otherwise, transform the list of indices into a tensor\n",
    "                _indices[s] = torch.LongTensor(_indices[s])\n",
    "                \n",
    "            # register the indices tensors as parameters of this module\n",
    "            self.register_buffer('indices_{}'.format(s), _indices[s])\n",
    "        \n",
    "    def forward(self, input: escnn.nn.GeometricTensor) -> escnn.nn.GeometricTensor:\n",
    "        r\"\"\"\n",
    "        \n",
    "        Run the norm-based max-pooling on the input tensor\n",
    "        \n",
    "        Args:\n",
    "            input (GeometricTensor): the input feature map\n",
    "\n",
    "        Returns:\n",
    "            the resulting feature map\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        assert input.type == self.in_type\n",
    "        \n",
    "        b, c, hi, wi = input.tensor.shape\n",
    "        \n",
    "        # compute the output shape (see 'torch.nn.MaxPool2D')\n",
    "        b, c, ho, wo = self.evaluate_output_shape(input.tensor.shape)\n",
    "        \n",
    "        # compute the squares of the values of each channel\n",
    "        # n = torch.mul(input.data, input.data)\n",
    "        n = input.tensor ** 2\n",
    "        \n",
    "        # pre-allocate the output tensor\n",
    "        output = torch.empty(b, c, ho, wo, device=input.tensor.device)\n",
    "        \n",
    "        # reshape the input to merge the spatial dimensions\n",
    "        input = input.tensor.reshape(b, c, -1)\n",
    "        \n",
    "        # iterate through all field sizes\n",
    "        for s, contiguous in self._contiguous.items():\n",
    "            indices = getattr(self, f\"indices_{s}\")\n",
    "            \n",
    "            if contiguous:\n",
    "                # if the fields were contiguous, we can use slicing\n",
    "                \n",
    "                # compute the norms\n",
    "                norms = n[:, indices[0]:indices[1], :, :]\\\n",
    "                        .view(b, -1, s, hi, wi)\\\n",
    "                        .sum(dim=2)\\\n",
    "                        .sqrt()\n",
    "                \n",
    "                # run max-pooling on the norms-tensor\n",
    "                _, indx = F.max_pool2d(norms,\n",
    "                                       self.kernel_size,\n",
    "                                       self.stride,\n",
    "                                       self.padding,\n",
    "                                       self.dilation,\n",
    "                                       self.ceil_mode,\n",
    "                                       return_indices=True)\n",
    "                \n",
    "                # in order to use the pooling indices computed for the norms to retrieve the fields, they need to be\n",
    "                # expanded in the inner field dimension\n",
    "                print(indx.shape)\n",
    "                indx = indx.view(b, -1, 1, ho * wo)\n",
    "                print(indx.shape)\n",
    "                indx = indx.expand(-1, -1, s, -1)\n",
    "                print(indx.shape)\n",
    "                \n",
    "                # retrieve the fields from the input tensor using the pooling indeces\n",
    "                output[:, indices[0]:indices[1], :, :] = input[:, indices[0]:indices[1], :]\\\n",
    "                                                              .view(b, -1, s, hi*wi)\\\n",
    "                                                              .gather(3, indx)\\\n",
    "                                                              .view(b, -1, ho, wo)\n",
    "                \n",
    "            else:\n",
    "                # otherwise we have to use indexing\n",
    "                \n",
    "                # compute the norms\n",
    "                norms = n[:, indices, :, :] \\\n",
    "                    .view(b, -1, s, hi, wi) \\\n",
    "                    .sum(dim=2) \\\n",
    "                    .sqrt()\n",
    "                \n",
    "                # run max-pooling on the norms-tensor\n",
    "                _, indx = F.max_pool2d(norms,\n",
    "                                       self.kernel_size,\n",
    "                                       self.stride,\n",
    "                                       self.padding,\n",
    "                                       self.dilation,\n",
    "                                       self.ceil_mode,\n",
    "                                       return_indices=True)\n",
    "                \n",
    "                # in order to use the pooling indices computed for the norms to retrieve the fields, they need to be\n",
    "                # expanded in the inner field dimension\n",
    "                print(indx.shape)\n",
    "                indx = indx.view(b, -1, 1, ho * wo)\n",
    "                print(indx.shape)\n",
    "                indx = indx.expand(-1, -1, s, -1)\n",
    "                print(indx.shape)\n",
    "\n",
    "                # retrieve the fields from the input tensor using the pooling indeces\n",
    "                output[:, indices, :, :] = input[:, indices, :] \\\n",
    "                    .view(b, -1, s, hi * wi) \\\n",
    "                    .gather(3, indx) \\\n",
    "                    .view(b, -1, ho, wo)\n",
    "        \n",
    "        # wrap the result in a GeometricTensor\n",
    "        return escnn.nn.GeometricTensor(output, self.out_type, coords=None)\n",
    "\n",
    "\n",
    "    def evaluate_output_shape(self, input_shape: Tuple[int, int, int, int, int]) -> Tuple[int, int, int, int, int]:\n",
    "        assert len(input_shape) == 4\n",
    "        assert input_shape[1] == self.in_type.size\n",
    "\n",
    "        b, c, hi, wi = input_shape\n",
    "\n",
    "        # compute the output shape (see 'torch.nn.MaxPool2D')\n",
    "        ho = math.floor(\n",
    "            (hi + 2 * self.padding[0] - self.dilation[0] * (self.kernel_size[0] - 1) - 1) / self.stride[0] + 1)\n",
    "        wo = math.floor(\n",
    "            (wi + 2 * self.padding[1] - self.dilation[1] * (self.kernel_size[1] - 1) - 1) / self.stride[1] + 1)\n",
    "\n",
    "        return b, self.out_type.size, ho, wo\n",
    "        \n",
    "    def check_equivariance(self, atol: float = 1e-6, rtol: float = 1e-5) -> List[Tuple[Any, float]]:\n",
    "    \n",
    "        # this kind of pooling is not really equivariant so we can not test equivariance\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 4, 32, 32)\n",
    "\n",
    "r2_act = gspaces.rot2dOnR2(N=-1)\n",
    "in_type = enn.FieldType(r2_act, [r2_act.trivial_repr]*4)\n",
    "print(in_type.gspace.dimensionality)\n",
    "x = in_type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpooling = NormMaxPool(\n",
    "    in_type=in_type,\n",
    "    kernel_size=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 16, 16])\n",
      "torch.Size([4, 4, 1, 256])\n",
      "torch.Size([4, 4, 1, 256])\n",
      "x.shape: torch.Size([4, 4, 32, 32])\n",
      "y.shape: torch.Size([4, 4, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "y = maxpooling(x)\n",
    "\n",
    "print(f\"x.shape: {x.tensor.shape}\")\n",
    "print(f\"y.shape: {y.tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormMaxPool3D(EquivariantModule):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 in_type: FieldType,\n",
    "                 kernel_size,\n",
    "                 stride=None,\n",
    "                 padding=0,\n",
    "                 dilation = 1,\n",
    "                 ceil_mode = False,\n",
    "                 ):\n",
    "        r\"\"\"\n",
    "        \n",
    "        Max-pooling based on the fields' norms. In a given window of shape :attr:`kernel_size`, for each\n",
    "        group of channels belonging to the same field, the field with the highest norm (as the length of the vector)\n",
    "        is preserved.\n",
    "        \n",
    "        Except :attr:`in_type`, the other parameters correspond to the ones of :class:`torch.nn.MaxPool2d`.\n",
    "        \n",
    "        .. warning ::\n",
    "            Even if the input tensor has a `coords` attribute, the output of this module will not have one.\n",
    "            \n",
    "        Args:\n",
    "            in_type (FieldType): the input field type\n",
    "            kernel_size: the size of the window to take a max over\n",
    "            stride: the stride of the window. Default value is :attr:`kernel_size`\n",
    "            padding: implicit zero padding to be added on both sides\n",
    "            dilation: a parameter that controls the stride of elements in the window\n",
    "            ceil_mode: when ``True``, will use ceil instead of floor to compute the output shape\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        assert isinstance(in_type.gspace, escnn.gspaces.GSpace)\n",
    "        assert in_type.gspace.dimensionality == 3\n",
    "\n",
    "        super(NormMaxPool3D, self).__init__()\n",
    "\n",
    "        self.space = in_type.gspace\n",
    "        self.in_type = in_type\n",
    "        self.out_type = in_type\n",
    "\n",
    "        if isinstance(kernel_size, int):\n",
    "            self.kernel_size = (kernel_size, kernel_size, kernel_size)\n",
    "        else:\n",
    "            self.kernel_size = kernel_size\n",
    "        \n",
    "        if isinstance(stride, int):\n",
    "            self.stride = (stride, stride, stride)\n",
    "        elif stride is None:\n",
    "            self.stride = self.kernel_size\n",
    "        else:\n",
    "            self.stride = stride\n",
    "        \n",
    "        if isinstance(padding, int):\n",
    "            self.padding = (padding, padding, padding)\n",
    "        else:\n",
    "            self.padding = padding\n",
    "        \n",
    "        if isinstance(dilation, int):\n",
    "            self.dilation = (dilation, dilation, dilation)\n",
    "        else:\n",
    "            self.dilation = dilation\n",
    "            \n",
    "        self.ceil_mode = ceil_mode\n",
    "        \n",
    "        self._nfields = None\n",
    "        \n",
    "        # group fields by their size and\n",
    "        #   - check if fields of the same size are contiguous\n",
    "        #   - retrieve the indices of the fields\n",
    "\n",
    "        # number of fields of each size\n",
    "        self._nfields = defaultdict(int)\n",
    "        \n",
    "        # indices of the channales corresponding to fields belonging to each group\n",
    "        _indices = defaultdict(lambda: [])\n",
    "        \n",
    "        # whether each group of fields is contiguous or not\n",
    "        self._contiguous = {}\n",
    "        \n",
    "        position = 0\n",
    "        last_size = None\n",
    "        for i, r in enumerate(self.in_type.representations):\n",
    "            \n",
    "            if r.size != last_size:\n",
    "                if not r.size in self._contiguous:\n",
    "                    self._contiguous[r.size] = True\n",
    "                else:\n",
    "                    self._contiguous[r.size] = False\n",
    "            last_size = r.size\n",
    "            \n",
    "            _indices[r.size] += list(range(position, position + r.size))\n",
    "            self._nfields[r.size] += 1\n",
    "            position += r.size\n",
    "        \n",
    "        for s, contiguous in self._contiguous.items():\n",
    "            if contiguous:\n",
    "                # for contiguous fields, only the first and last indices are kept\n",
    "                _indices[s] = torch.LongTensor([min(_indices[s]), max(_indices[s])+1])\n",
    "            else:\n",
    "                # otherwise, transform the list of indices into a tensor\n",
    "                _indices[s] = torch.LongTensor(_indices[s])\n",
    "                \n",
    "            # register the indices tensors as parameters of this module\n",
    "            self.register_buffer('indices_{}'.format(s), _indices[s])\n",
    "        \n",
    "    def forward(self, input: escnn.nn.GeometricTensor) -> escnn.nn.GeometricTensor:\n",
    "        r\"\"\"\n",
    "        \n",
    "        Run the norm-based max-pooling on the input tensor\n",
    "        \n",
    "        Args:\n",
    "            input (GeometricTensor): the input feature map\n",
    "\n",
    "        Returns:\n",
    "            the resulting feature map\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        assert input.type == self.in_type\n",
    "        \n",
    "        b, c, hi, wi, di = input.tensor.shape\n",
    "        \n",
    "        # compute the output shape (see 'torch.nn.MaxPool2D')\n",
    "        b, c, ho, wo, do = self.evaluate_output_shape(input.tensor.shape)\n",
    "        \n",
    "        # compute the squares of the values of each channel\n",
    "        # n = torch.mul(input.data, input.data)\n",
    "        n = input.tensor ** 2\n",
    "        \n",
    "        # pre-allocate the output tensor\n",
    "        output = torch.empty(b, c, ho, wo, do, device=input.tensor.device)\n",
    "        \n",
    "        # reshape the input to merge the spatial dimensions\n",
    "        input = input.tensor.reshape(b, c, -1) # b, c, hi*wi*di\n",
    "        \n",
    "        # iterate through all field sizes\n",
    "        for s, contiguous in self._contiguous.items():\n",
    "            indices = getattr(self, f\"indices_{s}\")\n",
    "            \n",
    "            if contiguous:\n",
    "                # if the fields were contiguous, we can use slicing\n",
    "                \n",
    "                # compute the norms\n",
    "                norms = n[:, indices[0]:indices[1], :, :, :]\\\n",
    "                        .view(b, -1, s, hi, wi, di)\\\n",
    "                        .sum(dim=2)\\\n",
    "                        .sqrt()\n",
    "                \n",
    "                # run max-pooling on the norms-tensor\n",
    "                _, indx = F.max_pool3d(norms,\n",
    "                                       self.kernel_size,\n",
    "                                       self.stride,\n",
    "                                       self.padding,\n",
    "                                       self.dilation,\n",
    "                                       self.ceil_mode,\n",
    "                                       return_indices=True)\n",
    "                \n",
    "                # in order to use the pooling indices computed for the norms to retrieve the fields, they need to be\n",
    "                # expanded in the inner field dimension\n",
    "                print(indx.shape)\n",
    "                indx = indx.view(b, -1, 1, ho * wo * do)\n",
    "                print(indx.shape)\n",
    "                indx = indx.expand(-1, -1, s, -1)\n",
    "                print(indx.shape)\n",
    "                \n",
    "                # retrieve the fields from the input tensor using the pooling indeces\n",
    "                output[:, indices[0]:indices[1], :, :, :] = input[:, indices[0]:indices[1], :]\\\n",
    "                                                              .view(b, -1, s, hi*wi*di)\\\n",
    "                                                              .gather(3, indx)\\\n",
    "                                                              .view(b, -1, ho, wo, do)\n",
    "                \n",
    "            else:\n",
    "                # otherwise we have to use indexing\n",
    "                \n",
    "                # compute the norms\n",
    "                norms = n[:, indices, :, :, :] \\\n",
    "                    .view(b, -1, s, hi, wi, di) \\\n",
    "                    .sum(dim=2) \\\n",
    "                    .sqrt()\n",
    "                \n",
    "                # run max-pooling on the norms-tensor\n",
    "                _, indx = F.max_pool3d(norms,\n",
    "                                       self.kernel_size,\n",
    "                                       self.stride,\n",
    "                                       self.padding,\n",
    "                                       self.dilation,\n",
    "                                       self.ceil_mode,\n",
    "                                       return_indices=True)\n",
    "                \n",
    "                # in order to use the pooling indices computed for the norms to retrieve the fields, they need to be\n",
    "                # expanded in the inner field dimension\n",
    "                print(indx.shape)\n",
    "                indx = indx.view(b, -1, 1, ho * wo * do)\n",
    "                print(indx.shape)\n",
    "                indx = indx.expand(-1, -1, s, -1)\n",
    "                print(indx.shape)\n",
    "\n",
    "                # retrieve the fields from the input tensor using the pooling indeces\n",
    "                output[:, indices, :, :, :] = input[:, indices, :] \\\n",
    "                    .view(b, -1, s, hi * wi * di) \\\n",
    "                    .gather(3, indx) \\\n",
    "                    .view(b, -1, ho, wo, do)\n",
    "        \n",
    "        # wrap the result in a GeometricTensor\n",
    "        return escnn.nn.GeometricTensor(output, self.out_type, coords=None)\n",
    "\n",
    "\n",
    "    def evaluate_output_shape(self, input_shape: Tuple[int, int, int, int, int]) -> Tuple[int, int, int, int, int]:\n",
    "        assert len(input_shape) == 5\n",
    "        assert input_shape[1] == self.in_type.size\n",
    "\n",
    "        b, c, hi, wi, di = input_shape\n",
    "\n",
    "        # compute the output shape (see 'torch.nn.MaxPool2D')\n",
    "        ho = math.floor(\n",
    "            (hi + 2 * self.padding[0] - self.dilation[0] * (self.kernel_size[0] - 1) - 1) / self.stride[0] + 1)\n",
    "        wo = math.floor(\n",
    "            (wi + 2 * self.padding[1] - self.dilation[1] * (self.kernel_size[1] - 1) - 1) / self.stride[1] + 1)\n",
    "        do = math.floor(\n",
    "            (di + 2 * self.padding[2] - self.dilation[2] * (self.kernel_size[2] - 1) - 1) / self.stride[2] + 1)\n",
    "\n",
    "        return b, self.out_type.size, ho, wo, do\n",
    "        \n",
    "    def check_equivariance(self, atol: float = 1e-6, rtol: float = 1e-5) -> List[Tuple[Any, float]]:\n",
    "    \n",
    "        # this kind of pooling is not really equivariant so we can not test equivariance\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 4, 32, 32, 10)\n",
    "\n",
    "r2_act = gspaces.rot2dOnR3(n=-1)\n",
    "in_type = enn.FieldType(r2_act, [r2_act.trivial_repr]*4)\n",
    "print(in_type.gspace.dimensionality)\n",
    "x = in_type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 16, 16, 10])\n",
      "torch.Size([4, 4, 1, 2560])\n",
      "torch.Size([4, 4, 1, 2560])\n",
      "torch.Size([4, 4, 32, 32, 10])\n",
      "torch.Size([4, 4, 16, 16, 10])\n"
     ]
    }
   ],
   "source": [
    "maxpooling = NormMaxPool3D(\n",
    "    in_type=in_type,\n",
    "    kernel_size=(2, 2, 1),\n",
    ")\n",
    "y = maxpooling(x)\n",
    "print(x.tensor.shape)\n",
    "print(y.tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 32, 32, 10])\n",
      "torch.Size([4, 4, 64, 64, 10])\n"
     ]
    }
   ],
   "source": [
    "up = enn.R3Upsampling(\n",
    "    in_type=in_type,\n",
    "    scale_factor=(2, 2, 1)\n",
    ")\n",
    "\n",
    "print(x.tensor.shape)\n",
    "z = up(x)\n",
    "print(z.tensor.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
