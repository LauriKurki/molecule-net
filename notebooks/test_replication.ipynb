{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import flax\n",
    "#from flax.training import train_state\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "from clu import metrics, metric_writers\n",
    "\n",
    "from typing import Any, Tuple, Optional, Dict\n",
    "\n",
    "from molnet import utils, train, hooks, train_state\n",
    "from molnet.models import create_model\n",
    "from molnet.data import input_pipeline\n",
    "from configs import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolnetTrainState(train_state.TrainState):\n",
    "    batch_stats: Dict[str, jnp.ndarray]\n",
    "    train_metrics: Any\n",
    "\n",
    "writer = metric_writers.create_default_writer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 09:28:56.295503: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n"
     ]
    }
   ],
   "source": [
    "config = test.get_config()\n",
    "config.root_dir = '/l/data/molnet/atom_maps/'\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "datarng, rng = jax.random.split(rng)\n",
    "\n",
    "datasets = input_pipeline.get_datasets(datarng, config)['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(config)\n",
    "x_init = next(datasets)[\"images\"]\n",
    "\n",
    "variables = model.init(rng, x_init, training=True)\n",
    "params, batch_stats = variables[\"params\"], variables[\"batch_stats\"]\n",
    "\n",
    "state = MolnetTrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    tx=optax.adamw(0.01),\n",
    "    batch_stats=batch_stats,\n",
    "    train_metrics=train.Metrics.empty()\n",
    ")\n",
    "\n",
    "log_hook = hooks.LogTrainingMetricsHook(writer, is_empty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    batch = next(datasets)\n",
    "\n",
    "    state, metrics = train.train_step(state, batch)\n",
    "    \n",
    "    state = state.replace(\n",
    "        train_metrics=state.train_metrics.merge(metrics)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create writer for logs\n",
    "workdir = tempfile.mkdtemp()\n",
    "\n",
    "writer = metric_writers.create_default_writer(workdir)\n",
    "writer.write_hparams(config.to_dict())\n",
    "\n",
    "# Save config to workdir\n",
    "config_path = os.path.join(workdir, \"config.yaml\")\n",
    "with open(config_path, \"w\") as f:\n",
    "    yaml.dump(config, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get datasets\n",
    "print(\"Loading datasets.\")\n",
    "rng = jax.random.PRNGKey(config.rng_seed)\n",
    "rng, data_rng = jax.random.split(rng)\n",
    "datasets = input_pipeline.get_datasets(data_rng, config)\n",
    "train_ds = datasets[\"train\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create model\n",
    "print(\"Creating model.\")\n",
    "x_init = next(train_ds)['images']\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "model = create_model(config)\n",
    "\n",
    "variables = model.init(init_rng, x_init, training=True)\n",
    "params = variables[\"params\"]\n",
    "batch_stats = variables[\"batch_stats\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(1, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(0., dtype=float32), count=Array(0, dtype=int32)))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create optimizer\n",
    "tx = utils.create_optimizer(config)\n",
    "\n",
    "# Create training state\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    tx=tx,\n",
    "    batch_stats=batch_stats,\n",
    "    best_params=params,\n",
    "    step_for_best_params=0,\n",
    "    metrics_for_best_params={},\n",
    "    train_metrics=train.Metrics.empty(),\n",
    ")\n",
    "print(state.train_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(9, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(3.8863802, dtype=float32), count=Array(8, dtype=int32)))\n",
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(10, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(4.306643, dtype=float32), count=Array(9, dtype=int32)))\n",
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(11, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(4.6948643, dtype=float32), count=Array(10, dtype=int32)))\n",
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(12, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(5.1066995, dtype=float32), count=Array(11, dtype=int32)))\n",
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(13, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(5.5362916, dtype=float32), count=Array(12, dtype=int32)))\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    batch = next(train_ds)\n",
    "    state, batch_metrics = train.train_step(state, batch)\n",
    "\n",
    "    state = state.replace(\n",
    "        train_metrics=state.train_metrics.merge(batch_metrics)\n",
    "    )\n",
    "\n",
    "    print(state.train_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating hooks.\n",
      "Starting training loop.\n",
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(1, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(1.4025555, dtype=float32), count=Array(1, dtype=int32)))\n",
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(1, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(1.3746758, dtype=float32), count=Array(1, dtype=int32)))\n",
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(1, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(1.3682373, dtype=float32), count=Array(1, dtype=int32)))\n",
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(1, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(1.289912, dtype=float32), count=Array(1, dtype=int32)))\n",
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(1, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(1.2165849, dtype=float32), count=Array(1, dtype=int32)))\n",
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(1, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(1.24633, dtype=float32), count=Array(1, dtype=int32)))\n",
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(1, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(1.152856, dtype=float32), count=Array(1, dtype=int32)))\n",
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(1, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(1.1117079, dtype=float32), count=Array(1, dtype=int32)))\n",
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(1, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(1.1363227, dtype=float32), count=Array(1, dtype=int32)))\n",
      "Metrics(_reduction_counter=_ReductionCounter(value=Array(1, dtype=int32)), loss=Metric.from_output.<locals>.FromOutput(total=Array(1.0822371, dtype=float32), count=Array(1, dtype=int32)))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create hooks\n",
    "print(\"Creating hooks.\")\n",
    "log_hook = hooks.LogTrainingMetricsHook(writer)\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting training loop.\")\n",
    "\n",
    "for step in range(config.num_train_steps):\n",
    "\n",
    "    #if step % config.log_every_steps == 0:\n",
    "    #    log_hook(state)\n",
    "\n",
    "    batch = next(train_ds)\n",
    "    state, batch_metrics = train.train_step(state, batch)\n",
    "    print(batch_metrics)\n",
    "    \n",
    "    #state = state.replace(\n",
    "    #    train_metrics=state.train_metrics.merge(batch_metrics)\n",
    "    #)\n",
    "    #log_hook.is_empty = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
