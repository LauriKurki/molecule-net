{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "from molnet.torch_models import create_model\n",
    "from molnet.data import input_pipeline\n",
    "from configs.tests import torch_attention_test\n",
    "from configs import root_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = torch_attention_test.get_config()\n",
    "config.root_dir = root_dirs.get_root_dir()\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "datarng, rng = jax.random.split(rng)\n",
    "\n",
    "ds = input_pipeline.get_pseudodatasets(datarng, config)\n",
    "train_loader = ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 128, 128, 10) (4, 5, 128, 128, 21) (4, 54, 5)\n",
      "float32 float32 float32\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "batch = next(train_loader)\n",
    "x, atom_map, xyz = batch['images'], batch['atom_map'], batch['xyz']\n",
    "\n",
    "print(x.shape, atom_map.shape, xyz.shape)\n",
    "print(x.dtype, atom_map.dtype, xyz.dtype)\n",
    "print(type(x), type(atom_map), type(xyz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "class LitModel(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch = jax.tree_util.tree_map(torch.from_numpy, batch)\n",
    "        x, atom_map, xyz = batch['images'], batch['atom_map'], batch['xyz']\n",
    "        x = x.to(device)\n",
    "        atom_map = atom_map.to(device)\n",
    "        pred = self.model(x)\n",
    "        z_slices = x.shape[-1]\n",
    "        loss = F.mse_loss(pred, atom_map[..., -z_slices:])\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        batch = jax.tree_util.tree_map(torch.from_numpy, batch)\n",
    "        x, atom_map, xyz = batch['images'], batch['atom_map'], batch['xyz']\n",
    "        x = x.to(device)\n",
    "        atom_map = atom_map.to(device)\n",
    "        pred = self.model(x)\n",
    "        z_slices = x.shape[-1]\n",
    "        loss = F.mse_loss(pred, atom_map[..., -z_slices:])\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = LitModel(\n",
    "    create_model(config.model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/kurkil1/.venvs/molnet/lib/python3.12/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(limit_train_batches=10, max_epochs=1, accelerator='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type          | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | model | AttentionUNet | 17.6 K | train\n",
      "------------------------------------------------\n",
      "17.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.6 K    Total params\n",
      "0.070     Total estimated model params size (MB)\n",
      "59        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Users/kurkil1/.venvs/molnet/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/10 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kurkil1/.venvs/molnet/lib/python3.12/site-packages/jax/_src/tree_util.py:344: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  return treedef.unflatten(f(*xs) for xs in zip(*all_leaves))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 10/10 [00:14<00:00,  0.68it/s, v_num=8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 10/10 [00:14<00:00,  0.67it/s, v_num=8]\n"
     ]
    }
   ],
   "source": [
    "ds = input_pipeline.get_pseudodatasets(datarng, config)\n",
    "train_loader = ds['train']\n",
    "\n",
    "trainer.fit(model=unet, train_dataloaders=train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
