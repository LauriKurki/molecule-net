{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 13:59:44.022375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from clu import metric_writers\n",
    "\n",
    "import optax\n",
    "\n",
    "from molnet.models import create_model\n",
    "from molnet.data import input_pipeline\n",
    "from molnet import train_state, loss, hooks\n",
    "\n",
    "from configs import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 13:59:52.703336: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 2460497826159879776\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 2460497826159879776\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 2460497826159879776\n"
     ]
    }
   ],
   "source": [
    "workdir = './test'\n",
    "writer = metric_writers.create_default_writer(workdir)\n",
    "\n",
    "config = test.get_config()\n",
    "config.root_dir = '/l/data/molnet/atom_maps/'\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "datasets = input_pipeline.get_datasets(rng, config)\n",
    "train_iter = datasets['train']\n",
    "\n",
    "model = create_model(config)\n",
    "variables = model.init(rng, next(train_iter)['images'], training=True)\n",
    "params = variables['params']\n",
    "batch_stats = variables['batch_stats']\n",
    "\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    batch_stats=batch_stats,\n",
    "    tx=optax.adamw(1e-3),\n",
    "    best_params=params,\n",
    "    metrics_for_best_params={},\n",
    "    step_for_best_params=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def predict_step(state, batch):\n",
    "    inputs, targets = batch['images'], batch['atom_map']\n",
    "    preds = state.apply_fn(\n",
    "        {'params': state.params, 'batch_stats': state.batch_stats},\n",
    "        inputs,\n",
    "        training=False,\n",
    "    )\n",
    "    preds_z = preds.shape[-2]\n",
    "    target = targets[..., -preds_z:, :]\n",
    "    loss_by_image = jnp.mean(\n",
    "        (preds - target) ** 2,\n",
    "        axis=(1, 2, 3, 4),\n",
    "    )\n",
    "    return inputs, target, preds, loss_by_image\n",
    "\n",
    "def predict_with_state(state, dataset, num_batches=1):\n",
    "    losses = []\n",
    "    preds = []\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        batch = next(dataset)\n",
    "        (\n",
    "            batch_inputs, batch_targets, batch_preds, batch_loss\n",
    "        ) = predict_step(state, batch)\n",
    "        inputs.append(batch_inputs)\n",
    "        targets.append(batch_targets)\n",
    "        preds.append(batch_preds)\n",
    "        losses.append(batch_loss)\n",
    "\n",
    "    inputs = jnp.concatenate(inputs)\n",
    "    targets = jnp.concatenate(targets)\n",
    "    preds = jnp.concatenate(preds)\n",
    "    losses = jnp.concatenate(losses)\n",
    "\n",
    "    return inputs, targets, preds, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: (8, 128, 128, 10, 1)\n",
      "targets: (8, 128, 128, 10, 5)\n",
      "preds: (8, 128, 128, 10, 5)\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    inputs, targets, preds, losses\n",
    ") = predict_with_state(\n",
    "    state, datasets['val'], 2\n",
    ")\n",
    "\n",
    "print(f\"inputs: {inputs.shape}\")\n",
    "print(f\"targets: {targets.shape}\")\n",
    "print(f\"preds: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = './test/'\n",
    "os.makedirs(outdir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['H', 'C', 'N', 'O', 'F']\n",
    "\n",
    "n_samples = inputs.shape[0]\n",
    "\n",
    "for sample in range(n_samples):\n",
    "    inp = inputs[sample]\n",
    "    target = targets[sample]\n",
    "    pred = preds[sample]\n",
    "    loss = losses[sample]\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 10), layout='constrained')\n",
    "    subfigs = fig.subfigures(1, 5, wspace=0.07, width_ratios=[1, 2, 2, 1, 1])\n",
    "\n",
    "    fig.suptitle(f'mse: {loss:.4f}', fontsize=16)\n",
    "    subfigs[0].suptitle(f'Input')\n",
    "    subfigs[1].suptitle(f'Prediction')\n",
    "    subfigs[2].suptitle(f'Target')\n",
    "    subfigs[3].suptitle(f'Prediction (sum over species)')\n",
    "    subfigs[4].suptitle(f'Target (sum over species)')\n",
    "\n",
    "    axs_input = subfigs[0].subplots(5, 1)\n",
    "    axs_pred = subfigs[1].subplots(10, 5)\n",
    "    axs_target = subfigs[2].subplots(10, 5)\n",
    "    axs_pred_sum = subfigs[3].subplots(10, 1)\n",
    "    axs_target_sum = subfigs[4].subplots(10, 1)\n",
    "\n",
    "    for i in range(10):\n",
    "        for j in range(5):\n",
    "            axs_pred[i, j].imshow(pred[..., i, j], cmap='gray')\n",
    "            axs_pred[i, j].set_xticks([])\n",
    "            axs_pred[i, j].set_yticks([])\n",
    "            axs_target[i, j].imshow(target[..., i, j], cmap='gray')\n",
    "            axs_target[i, j].set_xticks([])\n",
    "            axs_target[i, j].set_yticks([])\n",
    "\n",
    "    axs_input[0].set_ylabel('Far')\n",
    "    axs_input[-1].set_ylabel('Close')\n",
    "    for i in range(10):\n",
    "        axs_input[i//2].imshow(inp[..., i//2, 0], cmap='gray')\n",
    "        ps = axs_pred_sum[i].imshow(jnp.sum(pred[..., i, :], axis=-1), cmap='gray')\n",
    "        ts = axs_target_sum[i].imshow(jnp.sum(target[..., i, :], axis=-1), cmap='gray')\n",
    "    \n",
    "        for ax in [axs_pred_sum[i], axs_target_sum[i]]:\n",
    "            ax.set_aspect('equal')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        for ax in [axs_input, axs_pred_sum, axs_target_sum]:\n",
    "            ax[0].set_ylabel('Far')\n",
    "            ax[-1].set_ylabel('Close')\n",
    "\n",
    "    subfigs[3].colorbar(ps, ax=axs_pred_sum, location='right', shrink=0.5)\n",
    "    subfigs[4].colorbar(ts, ax=axs_target_sum, location='right', shrink=0.5)\n",
    "\n",
    "    for i, title in enumerate(titles):\n",
    "        axs_pred[0, i].set_title(title)\n",
    "        axs_target[0, i].set_title(title)\n",
    "        axs_pred[0, 0].set_ylabel('Far')\n",
    "        axs_pred[-1, 0].set_ylabel('Close')\n",
    "        axs_target[0, 0].set_ylabel('Far')\n",
    "        axs_target[-1, 0].set_ylabel('Close')\n",
    "\n",
    "\n",
    "    plt.savefig(f'{outdir}/sample_{sample}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = inputs.shape[0]\n",
    "\n",
    "for sample in range(n_samples):\n",
    "    inp = inputs[sample, ..., -1, 0]\n",
    "    pred = preds[sample].sum(axis=(-1, -2))\n",
    "    target = targets[sample].sum(axis=(-1, -2))\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    axs[0].imshow(inp, cmap='gray')\n",
    "    axs[0].set_title('Input')\n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_yticks([])\n",
    "\n",
    "    axs[1].imshow(pred, cmap='gray')\n",
    "    axs[1].set_title('Prediction')\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "\n",
    "    axs[2].imshow(target, cmap='gray')\n",
    "    axs[2].set_title('Target')\n",
    "    axs[2].set_xticks([])\n",
    "    axs[2].set_yticks([])\n",
    "\n",
    "    plt.savefig(f'{outdir}/total_{sample:02}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = hooks.PredictionHook(\n",
    "    workdir=workdir,\n",
    "    predict_fn=lambda state: predict_with_state(\n",
    "        state,\n",
    "        datasets['val'],\n",
    "        2\n",
    "    ),\n",
    "    writer=writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n",
      "ERROR:absl:Error in producer thread for AsyncWriter\n",
      "Traceback (most recent call last):\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/clu/asynclib.py\", line 135, in trap_errors\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/clu/metric_writers/summary_writer.py\", line 63, in write_images\n",
      "    tf.summary.image(key, value, step=step, max_outputs=value.shape[0])\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorboard/plugins/image/summary_v2.py\", line 146, in image\n",
      "    return tf.summary.write(\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorflow/python/ops/summary_ops_v2.py\", line 769, in write\n",
      "    op = smart_cond.smart_cond(\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorflow/python/framework/smart_cond.py\", line 53, in smart_cond\n",
      "    return true_fn()\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorflow/python/ops/summary_ops_v2.py\", line 757, in record\n",
      "    summary_tensor = tensor() if callable(tensor) else array_ops.identity(\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorboard/util/lazy_tensor_creator.py\", line 66, in __call__\n",
      "    self._tensor = self._tensor_callable()\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorboard/plugins/image/summary_v2.py\", line 121, in lazy_tensor\n",
      "    encoded_images = tf.map_fn(\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py\", line 648, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py\", line 576, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorflow/python/ops/map_fn.py\", line 640, in map_fn_v2\n",
      "    return map_fn(\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py\", line 576, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorflow/python/ops/map_fn.py\", line 498, in map_fn\n",
      "    _, r_a = while_loop.while_loop(\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorflow/python/ops/while_loop.py\", line 499, in while_loop\n",
      "    loop_vars = body(*loop_vars)\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorflow/python/ops/while_loop.py\", line 490, in <lambda>\n",
      "    body = lambda i, lv: (i + 1, orig_body(*lv))\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorflow/python/ops/map_fn.py\", line 488, in compute\n",
      "    result_value = autographed_fn(elems_value)\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/u/79/kurkil1/unix/.venvs/molnet/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 6656, in raise_from_not_ok_status\n",
      "    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__EncodePng_device_/job:localhost/replica:0/task:0/device:CPU:0}} image must have 1, 2, 3, or 4 channels, got 128 [Op:EncodePng] name: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 128, 128) (8, 128, 128) (8, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "hook(state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
