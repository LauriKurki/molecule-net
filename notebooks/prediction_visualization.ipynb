{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 10:31:22.094702: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'test' from 'configs' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmolnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_pipeline\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmolnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_state, loss, hooks\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfigs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m test\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'test' from 'configs' (unknown location)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from clu import metric_writers\n",
    "\n",
    "import optax\n",
    "\n",
    "from molnet.models import create_model\n",
    "from molnet.data import input_pipeline\n",
    "from molnet import train_state, loss, hooks\n",
    "\n",
    "from configs import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 14:03:54.202100: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 2460497826159879776\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 2460497826159879776\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 2460497826159879776\n"
     ]
    }
   ],
   "source": [
    "workdir = './test'\n",
    "writer = metric_writers.create_default_writer(workdir)\n",
    "\n",
    "config = test.get_config()\n",
    "config.root_dir = root_dirs.get_root_dir()\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "datasets = input_pipeline.get_datasets(rng, config)\n",
    "train_iter = datasets['train']\n",
    "\n",
    "model = create_model(config)\n",
    "variables = model.init(rng, next(train_iter)['images'], training=True)\n",
    "params = variables['params']\n",
    "batch_stats = variables['batch_stats']\n",
    "\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    batch_stats=batch_stats,\n",
    "    tx=optax.adamw(1e-3),\n",
    "    best_params=params,\n",
    "    metrics_for_best_params={},\n",
    "    step_for_best_params=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def predict_step(state, batch):\n",
    "    inputs, targets = batch['images'], batch['atom_map']\n",
    "    preds = state.apply_fn(\n",
    "        {'params': state.params, 'batch_stats': state.batch_stats},\n",
    "        inputs,\n",
    "        training=False,\n",
    "    )\n",
    "    preds_z = preds.shape[-2]\n",
    "    target = targets[..., -preds_z:, :]\n",
    "    loss_by_image = jnp.mean(\n",
    "        (preds - target) ** 2,\n",
    "        axis=(1, 2, 3, 4),\n",
    "    )\n",
    "    return inputs, target, preds, loss_by_image\n",
    "\n",
    "def predict_with_state(state, dataset, num_batches=1):\n",
    "    losses = []\n",
    "    preds = []\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        batch = next(dataset)\n",
    "        (\n",
    "            batch_inputs, batch_targets, batch_preds, batch_loss\n",
    "        ) = predict_step(state, batch)\n",
    "        inputs.append(batch_inputs)\n",
    "        targets.append(batch_targets)\n",
    "        preds.append(batch_preds)\n",
    "        losses.append(batch_loss)\n",
    "\n",
    "    inputs = jnp.concatenate(inputs)\n",
    "    targets = jnp.concatenate(targets)\n",
    "    preds = jnp.concatenate(preds)\n",
    "    losses = jnp.concatenate(losses)\n",
    "\n",
    "    return inputs, targets, preds, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: (8, 128, 128, 10, 1)\n",
      "targets: (8, 128, 128, 10, 5)\n",
      "preds: (8, 128, 128, 10, 5)\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    inputs, targets, preds, losses\n",
    ") = predict_with_state(\n",
    "    state, datasets['val'], 2\n",
    ")\n",
    "\n",
    "print(f\"inputs: {inputs.shape}\")\n",
    "print(f\"targets: {targets.shape}\")\n",
    "print(f\"preds: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = './test/'\n",
    "os.makedirs(outdir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['H', 'C', 'N', 'O', 'F']\n",
    "\n",
    "n_samples = inputs.shape[0]\n",
    "\n",
    "for sample in range(n_samples):\n",
    "    inp = inputs[sample]\n",
    "    target = targets[sample]\n",
    "    pred = preds[sample]\n",
    "    loss = losses[sample]\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 10), layout='constrained')\n",
    "    subfigs = fig.subfigures(1, 5, wspace=0.07, width_ratios=[1, 2, 2, 1, 1])\n",
    "\n",
    "    fig.suptitle(f'mse: {loss:.4f}', fontsize=16)\n",
    "    subfigs[0].suptitle(f'Input')\n",
    "    subfigs[1].suptitle(f'Prediction')\n",
    "    subfigs[2].suptitle(f'Target')\n",
    "    subfigs[3].suptitle(f'Prediction (sum over species)')\n",
    "    subfigs[4].suptitle(f'Target (sum over species)')\n",
    "\n",
    "    axs_input = subfigs[0].subplots(5, 1)\n",
    "    axs_pred = subfigs[1].subplots(10, 5)\n",
    "    axs_target = subfigs[2].subplots(10, 5)\n",
    "    axs_pred_sum = subfigs[3].subplots(10, 1)\n",
    "    axs_target_sum = subfigs[4].subplots(10, 1)\n",
    "\n",
    "    for i in range(10):\n",
    "        for j in range(5):\n",
    "            axs_pred[i, j].imshow(pred[..., i, j], cmap='gray')\n",
    "            axs_pred[i, j].set_xticks([])\n",
    "            axs_pred[i, j].set_yticks([])\n",
    "            axs_target[i, j].imshow(target[..., i, j], cmap='gray')\n",
    "            axs_target[i, j].set_xticks([])\n",
    "            axs_target[i, j].set_yticks([])\n",
    "\n",
    "    axs_input[0].set_ylabel('Far')\n",
    "    axs_input[-1].set_ylabel('Close')\n",
    "    for i in range(10):\n",
    "        axs_input[i//2].imshow(inp[..., i//2, 0], cmap='gray')\n",
    "        ps = axs_pred_sum[i].imshow(jnp.sum(pred[..., i, :], axis=-1), cmap='gray')\n",
    "        ts = axs_target_sum[i].imshow(jnp.sum(target[..., i, :], axis=-1), cmap='gray')\n",
    "    \n",
    "        for ax in [axs_pred_sum[i], axs_target_sum[i]]:\n",
    "            ax.set_aspect('equal')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        for ax in [axs_input, axs_pred_sum, axs_target_sum]:\n",
    "            ax[0].set_ylabel('Far')\n",
    "            ax[-1].set_ylabel('Close')\n",
    "\n",
    "    subfigs[3].colorbar(ps, ax=axs_pred_sum, location='right', shrink=0.5)\n",
    "    subfigs[4].colorbar(ts, ax=axs_target_sum, location='right', shrink=0.5)\n",
    "\n",
    "    for i, title in enumerate(titles):\n",
    "        axs_pred[0, i].set_title(title)\n",
    "        axs_target[0, i].set_title(title)\n",
    "        axs_pred[0, 0].set_ylabel('Far')\n",
    "        axs_pred[-1, 0].set_ylabel('Close')\n",
    "        axs_target[0, 0].set_ylabel('Far')\n",
    "        axs_target[-1, 0].set_ylabel('Close')\n",
    "\n",
    "\n",
    "    plt.savefig(f'{outdir}/sample_{sample}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = inputs.shape[0]\n",
    "\n",
    "for sample in range(n_samples):\n",
    "    inp = inputs[sample, ..., -1, 0]\n",
    "    pred = preds[sample].sum(axis=(-1, -2))\n",
    "    target = targets[sample].sum(axis=(-1, -2))\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    axs[0].imshow(inp, cmap='gray')\n",
    "    axs[0].set_title('Input')\n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_yticks([])\n",
    "\n",
    "    axs[1].imshow(pred, cmap='gray')\n",
    "    axs[1].set_title('Prediction')\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "\n",
    "    axs[2].imshow(target, cmap='gray')\n",
    "    axs[2].set_title('Target')\n",
    "    axs[2].set_xticks([])\n",
    "    axs[2].set_yticks([])\n",
    "\n",
    "    plt.savefig(f'{outdir}/total_{sample:02}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = hooks.PredictionHook(\n",
    "    workdir=workdir,\n",
    "    predict_fn=lambda state: predict_with_state(\n",
    "        state,\n",
    "        datasets['val'],\n",
    "        2\n",
    "    ),\n",
    "    writer=writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 9108667528181848758\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "(8, 128, 128, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/m/home/home7/79/kurkil1/unix/git/molecule-net/molnet/hooks.py:190\u001b[0m, in \u001b[0;36mPredictionHook.__call__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    187\u001b[0m preds_summed \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m))[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    188\u001b[0m targets_summed \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m))[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m inputs_summed\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m, inputs_summed\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m preds_summed\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m, preds_summed\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m targets_summed\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m, targets_summed\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mAssertionError\u001b[0m: (8, 128, 128, 1)"
     ]
    }
   ],
   "source": [
    "hook(state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
