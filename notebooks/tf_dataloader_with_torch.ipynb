{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import jax\n",
    "import torch.utils.data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ml_collections\n",
    "\n",
    "from molnet.data import input_pipeline\n",
    "from configs.tests import attention_test\n",
    "from configs import root_dirs\n",
    "\n",
    "from typing import Any, Dict, Tuple, Sequence, List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = attention_test.get_config()\n",
    "config.root_dir = root_dirs.get_root_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_images(\n",
    "    batch: Dict[str, tf.Tensor],\n",
    "    noise_std: float = 0.0,\n",
    "    seed: int = 0\n",
    ") -> Dict[str, tf.Tensor]:\n",
    "    \"\"\"Preprocesses images.\"\"\"\n",
    "    \n",
    "    x = batch[\"images\"]\n",
    "    y = batch[\"atom_map\"]\n",
    "\n",
    "    # Cast the images to float32.\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    y = tf.cast(y, tf.float32)\n",
    "\n",
    "    # Normalize the images to zero mean and unit variance.\n",
    "    # images are [X, Y, Z] - normalize each z slice separately\n",
    "    xmean = tf.reduce_mean(x, axis=(0, 1), keepdims=True)\n",
    "    xstd = tf.math.reduce_std(x, axis=(0, 1), keepdims=True)\n",
    "\n",
    "    x = (x - xmean) / xstd\n",
    "\n",
    "    # Interpolate to 16 z slices\n",
    "    #x = tf.image.resize(x, (x.shape[0], x.shape[1], 16), method='bilinear')\n",
    "\n",
    "    # Add noise to the images.\n",
    "    if noise_std > 0.0:\n",
    "        x = x + tf.random.normal(tf.shape(x), stddev=noise_std, seed=seed)\n",
    "\n",
    "    # Add channel dimension.\n",
    "    x = x[..., tf.newaxis]\n",
    "\n",
    "    # Swap the species channel to last\n",
    "    y = tf.transpose(y, perm=[1, 2, 3, 0])\n",
    "\n",
    "    batch[\"images\"] = x # [X, Y, Z, 1]\n",
    "    batch[\"atom_map\"] = y # [X, Y, Z, num_species]\n",
    "    \n",
    "    return batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader():\n",
    "    filenames = sorted(os.listdir(config.root_dir))\n",
    "    filenames = [\n",
    "    os.path.join(config.root_dir, f)\n",
    "    for f in filenames\n",
    "    if f.startswith(\"maps_\")\n",
    "    ]\n",
    "\n",
    "    element_spec = tf.data.Dataset.load(filenames[0]).element_spec\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "    ds = ds.interleave(\n",
    "        lambda path: tf.data.Dataset.load(path, element_spec=element_spec),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "        deterministic=True,\n",
    "    )\n",
    "\n",
    "    # Shuffle the dataset.\n",
    "    if config.shuffle_datasets:\n",
    "        ds = ds.shuffle(1000, seed=config.rng_seed)\n",
    "\n",
    "    # Repeat the dataset.\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    # batches consist of a dict {'images': image, 'xyz': xyz, 'atom_map': atom_map}\n",
    "    # pad xyz with zeros, its shape is [num_atoms, 5] - pad to [max_atoms, 5]\n",
    "    ds = ds.map(\n",
    "        lambda x: {\n",
    "            \"images\": x[\"images\"],\n",
    "            \"xyz\": tf.pad(x[\"xyz\"], [[0, config.max_atoms - tf.shape(x[\"xyz\"])[0]], [0, 0]]),\n",
    "            \"atom_map\": x[\"atom_map\"],\n",
    "        },\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "        deterministic=True,\n",
    "    )\n",
    "\n",
    "    # Preprocess images.\n",
    "    ds = ds.map(\n",
    "        lambda x: _preprocess_images(x, config.noise_std, seed=config.rng_seed),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "        deterministic=True,\n",
    "    )\n",
    "\n",
    "    # Batch the dataset.\n",
    "    ds = ds.batch(config.batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE).as_numpy_iterator()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 336318792119298919\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 336318792119298919\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 15664034803102229683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF mean time: 11.61 ms\n"
     ]
    }
   ],
   "source": [
    "loader = get_dataloader()\n",
    "tf_times = []\n",
    "for i in range(100):\n",
    "    t0 = time.time()\n",
    "    batch = next(loader)\n",
    "    t1 = time.time()\n",
    "    tf_times.append(t1 - t0)\n",
    "\n",
    "print(f\"TF mean time: {np.mean(tf_times)*1000:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 336318792119298919\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 336318792119298919\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 15664034803102229683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch mean time: 12.84 ms\n"
     ]
    }
   ],
   "source": [
    "loader = get_dataloader()\n",
    "\n",
    "torch_times = []\n",
    "for i in range(100):\n",
    "    t0 = time.time()\n",
    "    batch = next(loader)\n",
    "    images = torch.tensor(batch[\"images\"])\n",
    "    t1 = time.time()\n",
    "    torch_times.append(t1 - t0)\n",
    "\n",
    "print(f\"Torch mean time: {np.mean(torch_times)*1000:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "escnn-molnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
