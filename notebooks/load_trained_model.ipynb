{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "import functools\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ml_collections\n",
    "from clu import checkpoint\n",
    "\n",
    "\n",
    "from molnet import utils, train_state, train\n",
    "from molnet.data import input_pipeline_wds\n",
    "from molnet.models import create_model\n",
    "from configs import root_dirs\n",
    "from analyses import make_predictions\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#workdir = \"/u/79/kurkil1/unix/work/molnet/runs/attention-adam-3e-4/\"\n",
    "workdir = \"/Users/kurkil1/work/molnet/runs/attention-adam-3e-4/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_old_config(config):\n",
    "\n",
    "    model_config = ml_collections.ConfigDict()\n",
    "\n",
    "    kernel_size: int = config.model.kernel_size\n",
    "    num_blocks: int = len(config.model.channels)\n",
    "\n",
    "    model_config.encoder_kernel_size = [\n",
    "        [3, 3, 3] for _ in range(num_blocks)\n",
    "    ]\n",
    "\n",
    "    model_config.decoder_kernel_size = [\n",
    "        [3, 3, 3] for _ in range(num_blocks)\n",
    "    ]\n",
    "    \n",
    "    model_config.model_name = config.model.model_name\n",
    "    model_config.output_channels = config.model.output_channels\n",
    "    model_config.encoder_channels = [16, 32, 64, 128]\n",
    "    model_config.decoder_channels = [128, 64, 32, 16]\n",
    "    model_config.attention_channels = [16, 16, 16, 16]\n",
    "    model_config.conv_activation = \"relu\"\n",
    "    model_config.attention_activation = \"sigmoid\"\n",
    "    model_config.return_attention_maps = True\n",
    "\n",
    "    return model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_workdir(\n",
    "    workdir: str,\n",
    "    return_attention: bool\n",
    "):\n",
    "    # Load the model config\n",
    "    with open(os.path.join(workdir, \"config.yaml\"), \"rt\") as f:\n",
    "        config = yaml.unsafe_load(f)\n",
    "    config = ml_collections.ConfigDict(config)\n",
    "    config.root_dir = root_dirs.get_root_dir()\n",
    "    config.model.return_attention_maps = return_attention\n",
    "\n",
    "    print(config)\n",
    "\n",
    "    model_config = update_old_config(config)\n",
    "    print(model_config)\n",
    "\n",
    "    # Create the model\n",
    "    model = create_model(model_config)\n",
    "\n",
    "    checkpoint_dir = os.path.join(workdir, \"checkpoints\")\n",
    "    ckpt = checkpoint.Checkpoint(checkpoint_dir)\n",
    "\n",
    "    apply_fn = model.apply\n",
    "    tx = utils.create_optimizer(config)\n",
    "    restored_state = ckpt.restore(state=None)['state']\n",
    "\n",
    "    # Load the model state\n",
    "    state = train_state.EvaluationState.create(\n",
    "        apply_fn=apply_fn,\n",
    "        params=restored_state['params'],\n",
    "        batch_stats=restored_state['batch_stats'],\n",
    "        tx=tx,\n",
    "    )\n",
    "    state = jax.tree_util.tree_map(jnp.asarray, state)\n",
    "\n",
    "    return state, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 24\n",
      "dataset: edafm\n",
      "debug: false\n",
      "eval_every_steps: 10000\n",
      "learning_rate: 0.0003\n",
      "learning_rate_schedule: constant\n",
      "log_every_steps: 100\n",
      "max_atoms: 54\n",
      "model:\n",
      "  attention_channels:\n",
      "  - 16\n",
      "  - 16\n",
      "  - 16\n",
      "  - 16\n",
      "  channels:\n",
      "  - 16\n",
      "  - 32\n",
      "  - 64\n",
      "  - 128\n",
      "  kernel_size:\n",
      "  - 3\n",
      "  - 3\n",
      "  - 3\n",
      "  - 3\n",
      "  model_name: attention-unet\n",
      "  output_channels: 5\n",
      "  return_attention_maps: true\n",
      "momentum: null\n",
      "noise_std: 0.1\n",
      "num_eval_steps: 1000\n",
      "num_train_steps: 1000000\n",
      "optimizer: adam\n",
      "predict_every_steps: 10000\n",
      "predict_num_batches: 2\n",
      "predict_num_batches_at_end_of_training: 10\n",
      "rng_seed: 0\n",
      "root_dir: /Users/kurkil1/data/atom_maps\n",
      "shuffle_datasets: true\n",
      "train_molecules: !!python/tuple\n",
      "- 0\n",
      "- 230000\n",
      "val_molecules: !!python/tuple\n",
      "- 230000\n",
      "- 264000\n",
      "\n",
      "attention_activation: sigmoid\n",
      "attention_channels:\n",
      "- 16\n",
      "- 16\n",
      "- 16\n",
      "- 16\n",
      "conv_activation: relu\n",
      "decoder_channels:\n",
      "- 128\n",
      "- 64\n",
      "- 32\n",
      "- 16\n",
      "decoder_kernel_size:\n",
      "- - 3\n",
      "  - 3\n",
      "  - 3\n",
      "- - 3\n",
      "  - 3\n",
      "  - 3\n",
      "- - 3\n",
      "  - 3\n",
      "  - 3\n",
      "- - 3\n",
      "  - 3\n",
      "  - 3\n",
      "encoder_channels:\n",
      "- 16\n",
      "- 32\n",
      "- 64\n",
      "- 128\n",
      "encoder_kernel_size:\n",
      "- - 3\n",
      "  - 3\n",
      "  - 3\n",
      "- - 3\n",
      "  - 3\n",
      "  - 3\n",
      "- - 3\n",
      "  - 3\n",
      "  - 3\n",
      "- - 3\n",
      "  - 3\n",
      "  - 3\n",
      "model_name: attention-unet\n",
      "output_channels: 5\n",
      "return_attention_maps: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state, config = load_from_workdir(\n",
    "    workdir=workdir,\n",
    "    return_attention=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images (4, 128, 128, 10, 1)\n",
      "atom_map (4, 128, 128, 10, 5)\n",
      "xyz (4, 54, 5)\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "datarng, rng = jax.random.split(rng)\n",
    "config.train_molecules = (0, 64)\n",
    "config.val_molecules = (64, 96)\n",
    "config.batch_size = 4\n",
    "ds = input_pipeline_wds.get_datasets(\n",
    "    config\n",
    ")['val']\n",
    "\n",
    "batch = next(iter(ds))\n",
    "\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def predict(\n",
    "    state,\n",
    "    batch,\n",
    "):\n",
    "    inputs, targets = batch['images'], batch['atom_map']\n",
    "    preds, attention = state.apply_fn(\n",
    "        {'params': state.params, 'batch_stats': state.batch_stats},\n",
    "        inputs,\n",
    "        training=False,\n",
    "    )\n",
    "    loss_by_image = jnp.mean(\n",
    "        (preds - targets) ** 2,\n",
    "        axis=(1, 2, 3, 4),\n",
    "    )\n",
    "    return inputs, targets, preds, attention, loss_by_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets, preds, attention, loss_by_image = predict(\n",
    "    state,\n",
    "    batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: (4, 128, 128, 10, 1)\n",
      "targets: (4, 128, 128, 10, 5)\n",
      "preds: (4, 128, 128, 10, 5)\n",
      "loss_by_image: (4,)\n",
      "attention: (4, 16, 16, 10, 1)\n",
      "attention: (4, 32, 32, 10, 1)\n",
      "attention: (4, 64, 64, 10, 1)\n",
      "attention: (4, 128, 128, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"inputs: {inputs.shape}\")\n",
    "print(f\"targets: {targets.shape}\")\n",
    "print(f\"preds: {preds.shape}\")\n",
    "print(f\"loss_by_image: {loss_by_image.shape}\")\n",
    "for att in attention:\n",
    "    print(f\"attention: {att.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions.make_predictions(\n",
    "    workdir=workdir,\n",
    "    outputdir=os.path.join(workdir, \"analysis_mac\"),\n",
    "    num_batches=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
