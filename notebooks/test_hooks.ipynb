{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 12:31:10.192812: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import functools\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from absl import logging\n",
    "\n",
    "import flax\n",
    "import optax\n",
    "import chex\n",
    "from clu import metric_writers, parameter_overview\n",
    "\n",
    "from molnet import train_state, hooks, train, utils, loss\n",
    "from molnet.models import create_model\n",
    "\n",
    "from molnet.data import input_pipeline\n",
    "from configs import test\n",
    "\n",
    "from typing import Any, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.pmap, axis_name=\"device\")\n",
    "def eval_step(\n",
    "    state: train_state.TrainState,\n",
    "    images,\n",
    "    atom_map,\n",
    "):\n",
    "    \"\"\"Evaluation step.\"\"\"\n",
    "    preds = state.apply_fn(\n",
    "        {'params': state.params, 'batch_stats': state.batch_stats},\n",
    "        images,\n",
    "        training=False\n",
    "    )\n",
    "    preds_z = preds.shape[-2]\n",
    "    batch_loss = loss.mse(\n",
    "        preds,\n",
    "        atom_map[..., -preds_z:, :]\n",
    "    )\n",
    "\n",
    "    return train.Metrics.gather_from_model_output(\n",
    "        axis_name=\"device\",\n",
    "        loss=batch_loss,\n",
    "    )\n",
    "\n",
    "cross_replica_mean = jax.pmap(lambda x: jax.lax.pmean(x, 'x'), 'x') \n",
    "def evaluate_model(\n",
    "    state: train_state.TrainState,\n",
    "    datasets,\n",
    "    num_eval_steps: int,\n",
    "):\n",
    "    \"\"\"Evaluate over all datasets.\"\"\"\n",
    "\n",
    "    eval_metrics = {}\n",
    "    for split, data_iterator in datasets.items():\n",
    "        split_metrics = train.Metrics.empty()\n",
    "        split_metrics = flax.jax_utils.replicate(split_metrics)\n",
    "\n",
    "        state.replace(batch_stats=cross_replica_mean(state.batch_stats))\n",
    "        # Loop over graphs.\n",
    "        for step in range(num_eval_steps):\n",
    "            batch = next(device_batch(data_iterator))\n",
    "            #batch = jax.tree_util.tree_map(jnp.asarray, batch)\n",
    "           \n",
    "            # Evaluate the model.\n",
    "            batch_metrics = eval_step(state, batch['images'], batch['atom_map'])\n",
    "\n",
    "            split_metrics = split_metrics.merge(batch_metrics)\n",
    "\n",
    "        split_metrics = flax.jax_utils.unreplicate(split_metrics)\n",
    "        eval_metrics[split + \"_eval\"] = split_metrics\n",
    "\n",
    "    return eval_metrics  \n",
    "          \n",
    "@functools.partial(jax.pmap, axis_name=\"device\")\n",
    "def train_step(\n",
    "    state: train_state.TrainState,\n",
    "    images,\n",
    "    atom_map,\n",
    "    rng: chex.PRNGKey,\n",
    "):\n",
    "    \"\"\"Train step.\"\"\"\n",
    "\n",
    "    def loss_fn(params):\n",
    "        preds, updates = state.apply_fn(\n",
    "            {'params': params, 'batch_stats': state.batch_stats},\n",
    "            images,\n",
    "            training=True,\n",
    "            mutable='batch_stats',\n",
    "        )\n",
    "        preds_z = preds.shape[-2]\n",
    "        batch_loss = loss.mse(\n",
    "            preds,\n",
    "            atom_map[..., -preds_z:, :]\n",
    "        )\n",
    "\n",
    "        return batch_loss, (preds, updates)\n",
    "\n",
    "    # Compute loss and gradients\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (batch_loss, (_, updates)), grad = grad_fn(state.params)\n",
    "\n",
    "    # Average gradients across devices\n",
    "    grads = jax.lax.pmean(grad, axis_name=\"device\")\n",
    "    state = state.apply_gradients(\n",
    "        grads=grads,\n",
    "    )\n",
    "    state = state.replace(batch_stats=updates[\"batch_stats\"])\n",
    "\n",
    "    batch_metrics = train.Metrics.gather_from_model_output(\n",
    "        axis_name=\"device\",\n",
    "        loss=batch_loss,\n",
    "    )\n",
    "    return state, batch_metrics\n",
    "\n",
    "\n",
    "def device_batch(\n",
    "    batch_iterator\n",
    "):\n",
    "    \"\"\"Batches a set of inputs to the size of the number of devices.\"\"\"\n",
    "    num_devices = jax.local_device_count()\n",
    "    batch = []\n",
    "    for idx, b in enumerate(batch_iterator):\n",
    "        if idx % num_devices == num_devices - 1:\n",
    "            batch.append(b)\n",
    "            batch = jax.tree_util.tree_map(lambda *x: jnp.stack(x, axis=0), *batch)\n",
    "            yield batch\n",
    "\n",
    "            batch = []\n",
    "        else:\n",
    "            batch.append(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 12:31:51.131422: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "config = test.get_config()\n",
    "config.root_dir = '/l/data/molnet/atom_maps'\n",
    "config.workdir = tempfile.mkdtemp()\n",
    "\n",
    "# Create writer for logs\n",
    "writer = metric_writers.create_default_writer(config.workdir)\n",
    "writer.write_hparams(config.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n"
     ]
    }
   ],
   "source": [
    "# Get datasets\n",
    "rng = jax.random.PRNGKey(config.rng_seed)\n",
    "rng, data_rng = jax.random.split(rng)\n",
    "datasets = input_pipeline.get_datasets(data_rng, config)\n",
    "train_ds = datasets[\"train\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:1: Invalid control characters encountered in text.\n",
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:337] Error parsing text-format tensorflow.data.experimental.DistributedSnapshotMetadata: 1:3: Expected identifier, got: 12126270835042841805\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "import flax.jax_utils\n",
    "\n",
    "x_init = next(train_ds)['images']\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "model = create_model(config)\n",
    "\n",
    "variables = model.init(init_rng, x_init, training=True)\n",
    "params = variables[\"params\"]\n",
    "batch_stats = variables[\"batch_stats\"]\n",
    "parameter_overview.log_parameter_overview(params)\n",
    "\n",
    "# Create optimizer\n",
    "tx = utils.create_optimizer(config)\n",
    "\n",
    "# Create training state\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    tx=tx,\n",
    "    batch_stats=batch_stats,\n",
    "    best_params=params,\n",
    "    step_for_best_params=0,\n",
    "    metrics_for_best_params={},\n",
    "    train_metrics=train.Metrics.empty(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up checkpointing\n",
    "checkpoint_path = os.path.join(config.workdir, \"checkpoint\")\n",
    "checkpoint_hook = hooks.CheckpointHook(\n",
    "    checkpoint_path, max_keep=1\n",
    ")\n",
    "state = checkpoint_hook.restore_or_init(state)\n",
    "initial_step = state.get_step()\n",
    "\n",
    "# Replicate states across devices\n",
    "state = flax.jax_utils.replicate(state)\n",
    "\n",
    "train_metrics_hook = hooks.LogTrainMetricsHook(\n",
    "    writer,\n",
    ")\n",
    "evaluate_model_hook = hooks.EvaluateModelHook(\n",
    "    evaluate_model_fn=lambda state: evaluate_model(\n",
    "        state,\n",
    "        datasets,\n",
    "        config.num_eval_steps,\n",
    "    ),\n",
    "    writer=writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/m/home/home7/79/kurkil1/unix/git/molecule-net/molnet/hooks.py:114\u001b[0m, in \u001b[0;36mEvaluateModelHook.__call__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    111\u001b[0m     state: train_state\u001b[38;5;241m.\u001b[39mTrainState,\n\u001b[1;32m    112\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m train_state\u001b[38;5;241m.\u001b[39mTrainState:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# Evaluate the model.\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     eval_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_model_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# Compute and write metrics.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m eval_metrics:\n",
      "Cell \u001b[0;32mIn[31], line 16\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     10\u001b[0m state \u001b[38;5;241m=\u001b[39m flax\u001b[38;5;241m.\u001b[39mjax_utils\u001b[38;5;241m.\u001b[39mreplicate(state)\n\u001b[1;32m     12\u001b[0m train_metrics_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mLogTrainMetricsHook(\n\u001b[1;32m     13\u001b[0m     writer,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m evaluate_model_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mEvaluateModelHook(\n\u001b[0;32m---> 16\u001b[0m     evaluate_model_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m state: \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_eval_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     21\u001b[0m     writer\u001b[38;5;241m=\u001b[39mwriter,\n\u001b[1;32m     22\u001b[0m )\n",
      "Cell \u001b[0;32mIn[27], line 44\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(state, datasets, num_eval_steps)\u001b[0m\n\u001b[1;32m     40\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(device_batch(data_iterator))\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m#batch = jax.tree_util.tree_map(jnp.asarray, batch)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m    \n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# Evaluate the model.\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     batch_metrics \u001b[38;5;241m=\u001b[39m \u001b[43meval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43matom_map\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     split_metrics \u001b[38;5;241m=\u001b[39m split_metrics\u001b[38;5;241m.\u001b[39mmerge(batch_metrics)\n\u001b[1;32m     48\u001b[0m split_metrics \u001b[38;5;241m=\u001b[39m flax\u001b[38;5;241m.\u001b[39mjax_utils\u001b[38;5;241m.\u001b[39munreplicate(split_metrics)\n",
      "File \u001b[0;32m~/.venvs/molnet/lib/python3.10/site-packages/jax/_src/array.py:293\u001b[0m, in \u001b[0;36mArrayImpl.__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__bool__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m   \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_bool_conversion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value)\n",
      "File \u001b[0;32m~/.venvs/molnet/lib/python3.10/site-packages/jax/_src/core.py:676\u001b[0m, in \u001b[0;36mcheck_bool_conversion\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    673\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe truth value of an empty array is ambiguous. Use\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    674\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `array.size > 0` to check that an array is not empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 676\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe truth value of an array with more than one element\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    677\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is ambiguous. Use a.any() or a.all()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "state = evaluate_model_hook(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(device_batch(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
